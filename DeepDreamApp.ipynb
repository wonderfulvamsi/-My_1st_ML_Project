{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepDreamApp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/wonderfulvamsi/DEEPDREAM/blob/master/DeepDream.ipynb",
      "authorship_tag": "ABX9TyOpjyFdIcJSNr/UPMp8jVxD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wonderfulvamsi/-My_1st_ML_Project/blob/master/DeepDreamApp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NouACVE_zs5y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f3cb1a8e-96ed-4b47-a038-5efdc9a92dc8"
      },
      "source": [
        "%%writefile DeepDreamApp.py\n",
        "\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "import numpy as np\n",
        "#from matplotlib import pyplot\n",
        "\n",
        "from PIL import Image, ImageFilter, ImageChops\n",
        "\n",
        "import streamlit as st\n",
        "\n",
        "#--------------------------------------FrontEnd\n",
        "\n",
        "st.title('Deep Dream <3')\n",
        "st.write('This lets you to visualize what each layer of your DNN learnt to recognize')\n",
        "st.markdown('we use VGG16 as default in this app')\n",
        "\n",
        "IMAGE_PATH = st.file_uploader(\"Upload Content image...\", type=\"jpg\")\n",
        "\n",
        "if IMAGE_PATH is not None:\n",
        "    st.image(IMAGE_PATH, caption='Uploaded Content Image.', use_column_width=True)\n",
        "    img = Image.open(IMAGE_PATH)\n",
        "\n",
        "# Deep dream configs\n",
        "\n",
        "LAYER_ID = 28 # The layer to maximize the activations through\n",
        "\n",
        "NUM_ITERATIONS = 5 # Number of iterations to update the input image with the layer's gradient\n",
        "\n",
        "LR = 0.2\n",
        "\n",
        "# We downscale the image recursively, apply the deep dream computation, scale up, and then blend with the original image \n",
        "# to achieve better result.\n",
        "NUM_DOWNSCALES = 20\n",
        "\n",
        "BLEND_ALPHA = 0.6\n",
        "\n",
        "CUDA_ENABLED = False\n",
        "\n",
        "img_size = None\n",
        "Model = None\n",
        "\n",
        "if st.button(\"Run on my own model\"):\n",
        "  img_size=st.number_input('Image size',min_value=1,max_value=2000,step=1)\n",
        "  Model=st.file_uploader(\"Upload your costume PyTorch model\",type=['pt','pth'])\n",
        "  Model=torch.load(Model)\n",
        "\n",
        "if img_size is None:\n",
        "  img_size = 224\n",
        "\n",
        "if Model is None:\n",
        "  Model=models.vgg16(pretrained=True)\n",
        "\n",
        "if Model is not None:\n",
        "  st.write(\"Model Downloaded...\")\n",
        "\n",
        "modules = list(Model.features.modules())\n",
        "st.write(\"Layers in the model..\")\n",
        "\n",
        "layerno=0\n",
        "\n",
        "for l in modules[0]:\n",
        "  layerno+=1\n",
        "  st.write(\"Layer\",layerno,\" \",l)\n",
        "\n",
        "layer_to_dream = st.slider('Select the layer',min_value=1,max_value=(len(modules)-1),step=1)\n",
        "\n",
        "\n",
        "\n",
        "class DeepDream:\n",
        "    def __init__(self, image):\n",
        "        self.image = image\n",
        "        self.model = Model\n",
        "        if CUDA_ENABLED:\n",
        "            self.model = self.model.cuda()\n",
        "        self.modules = list(self.model.features.modules())\n",
        "        \n",
        "                # vgg16 use 224x224 images\n",
        "        imgSize = img_size\n",
        "        self.transformMean = [0.485, 0.456, 0.406]\n",
        "        self.transformStd = [0.229, 0.224, 0.225]\n",
        "        self.transformNormalise = transforms.Normalize(\n",
        "            mean=self.transformMean,\n",
        "            std=self.transformStd\n",
        "        )\n",
        "        \n",
        "        self.transformPreprocess = transforms.Compose([\n",
        "            transforms.Resize((imgSize, imgSize)),\n",
        "            transforms.ToTensor(),\n",
        "            self.transformNormalise\n",
        "        ])\n",
        "        \n",
        "        self.tensorMean = torch.Tensor(self.transformMean)\n",
        "        if CUDA_ENABLED:\n",
        "            self.tensorMean = self.tensorMean.cuda()\n",
        "\n",
        "        self.tensorStd = torch.Tensor(self.transformStd)\n",
        "        if CUDA_ENABLED:\n",
        "            self.tensorStd = self.tensorStd.cuda()\n",
        "\n",
        "    def toImage(self, input):\n",
        "        return input * self.tensorStd + self.tensorMean\n",
        "\n",
        "\n",
        "class DeepDream(DeepDream):\n",
        "    def deepDream(self, image, layer, iterations, lr):\n",
        "        transformed = self.transformPreprocess(image).unsqueeze(0)\n",
        "        if CUDA_ENABLED:\n",
        "            transformed = transformed.cuda()\n",
        "        input = torch.autograd.Variable(transformed, requires_grad=True)\n",
        "        self.model.zero_grad()\n",
        "        for _ in range(iterations):\n",
        "            out = input\n",
        "            for layerId in range(layer):\n",
        "                out = self.modules[layerId + 1](out)\n",
        "            loss = out.norm()\n",
        "            loss.backward()\n",
        "            input.data = input.data + lr * input.grad.data\n",
        "\n",
        "        input = input.data.squeeze()\n",
        "        input.transpose_(0,1)\n",
        "        input.transpose_(1,2)\n",
        "        input = np.clip(self.toImage(input), 0, 1)\n",
        "        return Image.fromarray(np.uint8(input*255))\n",
        "\n",
        "\n",
        "class DeepDream(DeepDream):\n",
        "    def deepDreamRecursive(self, image, layer, iterations, lr, num_downscales):\n",
        "        if num_downscales > 0:\n",
        "            # scale down the image\n",
        "            image_small = image.filter(ImageFilter.GaussianBlur(2))\n",
        "            small_size = (int(image.size[0]/2), int(image.size[1]/2))            \n",
        "            if (small_size[0] == 0 or small_size[1] == 0):\n",
        "                small_size = image.size\n",
        "            image_small = image_small.resize(small_size, Image.ANTIALIAS)\n",
        "            # run deepDreamRecursive on the scaled down image\n",
        "            image_small = self.deepDreamRecursive(image_small, layer, iterations, lr, num_downscales-1)\n",
        "            \n",
        "            # Scale up the result image to the original size\n",
        "            image_large = image_small.resize(image.size, Image.ANTIALIAS)\n",
        "            \n",
        "            # Blend the two image\n",
        "            image = ImageChops.blend(image, image_large, BLEND_ALPHA)\n",
        "        img_result = self.deepDream(image, layer, iterations, lr)\n",
        "        img_result = img_result.resize(image.size)\n",
        "        return img_result\n",
        "\n",
        "    def deepDreamProcess(self, layerID):\n",
        "        return self.deepDreamRecursive(self.image, layerID, NUM_ITERATIONS, LR, NUM_DOWNSCALES)\n",
        "\n",
        "def Dreaming(layerID):\n",
        "   img_deep_dream = DeepDream(img).deepDreamProcess(layerID)\n",
        "\n",
        "   st.image(img_deep_dream,caption='Dreamt image..',use_column_width=True)\n",
        "\n",
        "if st.button(\"Submit\"):\n",
        "  Dreaming(layer_to_dream)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting DeepDreamApp.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tubujNxb_feB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install streamlit -q"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sMJHUdK_sVD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "1076a505-8c6e-459d-cb48-6f31101802ce"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -qq ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-03 13:47:06--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.84.169.173, 52.54.253.53, 107.23.162.152, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.84.169.173|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.15’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab   9%[>                   ]   1.24M  5.84MB/s               \rngrok-stable-linux- 100%[===================>]  13.13M  36.0MB/s    in 0.4s    \n",
            "\n",
            "2020-07-03 13:47:06 (36.0 MB/s) - ‘ngrok-stable-linux-amd64.zip.15’ saved [13773305/13773305]\n",
            "\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS69bkXb_27j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e6f23359-d250-4dba-d460-d83966e274d4"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 8501 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://ff0387b0bc5f.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfecXVOwAAIf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "6a8341f8-e972-4b34-b086-975ce98f9b32"
      },
      "source": [
        "!streamlit run DeepDreamApp.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.67.253.62:8501\u001b[0m\n",
            "\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0eiO4ukIJ54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}